{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Burgers' equation\n",
    "\n",
    "$\\partial_t u=-u u_x+v u_{x x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide a simple example of the DeepMoD algorithm by applying it on the Burgers' equation. \n",
    "\n",
    "We start by importing the required libraries and setting the plotting style:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# DeePyMoD imports\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.data import Dataset, get_train_test_loader\n",
    "from deepymod.data.samples import Subsample_random\n",
    "from deepymod.data.burgers import burgers_delta\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.model.library import Library1D\n",
    "from deepymod.model.sparse_estimators import Threshold\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import Periodic, TrainTest, TrainTestPeriodic\n",
    "import intel_npu_acceleration_library\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Create all the argument we need to create a Burgers dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Making dataset\n",
    "v = 0.1\n",
    "A = 1.0\n",
    "\n",
    "x = torch.linspace(-3, 4, 100)\n",
    "t = torch.linspace(0.5, 5.0, 50)\n",
    "load_kwargs = {\"x\": x, \"t\": t, \"v\": v, \"A\": A}\n",
    "preprocess_kwargs = {\"noise_level\": 0.05}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pass this function to the dataset class, which then adds noise to it, normalizes the coordinates and performs random subsampling to it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset = Dataset(\n",
    "    burgers_delta,\n",
    "    load_kwargs=load_kwargs,\n",
    "    preprocess_kwargs=preprocess_kwargs,\n",
    "    subsampler=Subsample_random,\n",
    "    subsampler_kwargs={\"number_of_samples\": 2000},\n",
    "    device=device,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it to get an idea of the data. As we can see, $X$ has 2 dimensions, $\\{x, t\\}$, while $y$ has only one, $\\{u\\}$. Always explicity set the shape (i.e. $N\\times 1$, not $N$) or you'll get errors. We also added 5% of noise."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "coords = dataset.get_coords().cpu()\n",
    "data = dataset.get_data().cpu()\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.scatter(coords[:, 1], coords[:, 0], c=data[:, 0], marker=\"x\", s=10)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"t\")\n",
    "fig.colorbar(mappable=im)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now also wish to split the data into a train and test split, specifically into loaders, which handle the logic of passing the samples to the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_dataloader, test_dataloader = get_train_test_loader(dataset, train_test_split=0.8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring DeepMoD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the function approximator: Here the first argument is the number of input and the last argument the number of output layers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "network = NN(2, [50, 50, 50, 50], 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the library function: We select athe library with a 2D spatial input. Note that that the max differential order has been pre-determined here out of convinience. So, for poly_order 2 the library contains the following 12 terms:\n",
    "* [$1, u_x, u_{xx}, u_{xxx}, u, u u_{x}, u u_{xx}, u u_{xxx}, u^2, u^2 u_{x}, u^2 u_{xx}, u^2 u_{xxx}$]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "library = Library1D(poly_order=2, diff_order=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the sparsity estimator and sparsity scheduler used. In this case we use the most basic threshold-based Lasso estimator and a scheduler that asseses the validation loss after a given patience. If that value is smaller than 1e-5, the algorithm is converged.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "estimator = Threshold(0.1)\n",
    "sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=200, delta=1e-5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the sparsity estimator "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "constraint = LeastSquares()\n",
    "# Configuration of the sparsity scheduler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the model and send it to the GPU and select the optimizer "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = DeepMoD(network, library, estimator, constraint).to(device)\n",
    "\n",
    "# Defining optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DeepMoD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run DeepMoD using all the options we have set, the training and test loaders:\n",
    "* The directory where the tensorboard file is written (log_dir)\n",
    "* The maximum number of iterations performed (max_iterations)\n",
    "* The absolute change in L1 norm considered converged (delta)\n",
    "* The amount of epochs over which the absolute change in L1 norm is calculated (patience)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%time\n",
    "foldername = \"./data/deepymod/burgers/\"\n",
    "train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    sparsity_scheduler,\n",
    "    log_dir=foldername,\n",
    "    exp_ID=\"Test\",\n",
    "    write_iterations=25,\n",
    "    max_iterations=100000,\n",
    "    delta=1e-4,\n",
    "    patience=200,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from deepymod.analysis import load_tensorboard\n",
    "\n",
    "history = load_tensorboard(foldername)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for history_key in history.keys():\n",
    "    history_key_parts = history_key.split(\"_\")\n",
    "    if history_key_parts[0] == \"loss\":\n",
    "        if history_key_parts[-1] == \"0\":\n",
    "            axs[0].semilogy(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[1] + \"_\" + history_key_parts[-1],\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "        elif history_key_parts[-1] == \"1\":\n",
    "            axs[0].semilogy(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[1] + \"_\" + history_key_parts[-1],\n",
    "                linestyle=\":\",\n",
    "            )\n",
    "        else:\n",
    "            axs[0].semilogy(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[1] + \"_\" + history_key_parts[-1],\n",
    "                linestyle=\"-\",\n",
    "            )\n",
    "        if history_key_parts[0] == \"remaining\":\n",
    "            axs[0].semilogy(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[1]\n",
    "                + \"_\"\n",
    "                + history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4],\n",
    "                linestyle=\"-.\",\n",
    "            )\n",
    "    if history_key_parts[0] == \"coeffs\":\n",
    "        if history_key_parts[2] == \"0\":\n",
    "            axs[1].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[2]\n",
    "                + \"_\"\n",
    "                + history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4],\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "        elif history_key_parts[2] == \"1\":\n",
    "            axs[1].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[2]\n",
    "                + \"_\"\n",
    "                + history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4],\n",
    "                linestyle=\":\",\n",
    "            )\n",
    "        else:\n",
    "            axs[1].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[2]\n",
    "                + \"_\"\n",
    "                + history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4],\n",
    "                linestyle=\"-\",\n",
    "            )\n",
    "    if history_key_parts[0] == \"unscaled\":\n",
    "        if history_key_parts[3] == \"0\":\n",
    "            axs[2].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4]\n",
    "                + \"_\"\n",
    "                + history_key_parts[5],\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "        elif history_key_parts[3] == \"1\":\n",
    "            axs[2].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4]\n",
    "                + \"_\"\n",
    "                + history_key_parts[5],\n",
    "                linestyle=\":\",\n",
    "            )\n",
    "        else:\n",
    "            axs[2].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4]\n",
    "                + \"_\"\n",
    "                + history_key_parts[5],\n",
    "                linestyle=\"-\",\n",
    "            )\n",
    "    if history_key_parts[0] == \"estimator\":\n",
    "        if history_key_parts[3] == \"0\":\n",
    "            axs[3].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4]\n",
    "                + \"_\"\n",
    "                + history_key_parts[5],\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "        elif history_key_parts[3] == \"1\":\n",
    "            axs[3].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4]\n",
    "                + \"_\"\n",
    "                + history_key_parts[5],\n",
    "                linestyle=\":\",\n",
    "            )\n",
    "        else:\n",
    "            axs[3].plot(\n",
    "                history[history_key],\n",
    "                label=history_key_parts[3]\n",
    "                + \"_\"\n",
    "                + history_key_parts[4]\n",
    "                + \"_\"\n",
    "                + history_key_parts[5],\n",
    "                linestyle=\"-\",\n",
    "            )\n",
    "\n",
    "# axs[0].set_ylim([-2, 2])\n",
    "axs[1].set_ylim([-2, 2])\n",
    "axs[2].set_ylim([-2, 2])\n",
    "axs[3].set_ylim([-2, 2])\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "axs[2].legend()\n",
    "axs[3].legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The physical coefficients"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.constraint_coeffs()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity masks provide the active and non-active terms in the PDE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimatior_coeffs gives the magnitude of the active terms:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.estimator_coeffs()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepymod_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
